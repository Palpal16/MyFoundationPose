{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee4752f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_attachment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc84b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyrender\n",
    "except:\n",
    "    print('running it again')\n",
    "\n",
    "import pyrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate system transformation (OpenCV cam to OpenGL cam)\n",
    "cvcam_in_glcam = np.array([[1, 0, 0, 0],\n",
    "                          [0, -1, 0, 0],\n",
    "                          [0, 0, -1, 0],\n",
    "                          [0, 0, 0, 1]])\n",
    "\n",
    "def render_mesh_at_pose(mesh, pose, K, H, W, zfar=100):\n",
    "    # Transform mesh to OpenGL camera frame\n",
    "    mesh_transformed = mesh.copy()\n",
    "    mesh_transformed.apply_transform(cvcam_in_glcam @ pose)\n",
    "    \n",
    "    # Setup pyrender scene\n",
    "    scene = pyrender.Scene(ambient_light=[1., 1., 1.], bg_color=[0, 0, 0])\n",
    "    \n",
    "    # Add camera\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.1, zfar=zfar\n",
    "    )\n",
    "    scene.add(camera, pose=np.eye(4))\n",
    "    \n",
    "    # Add mesh\n",
    "    pyrender_mesh = pyrender.Mesh.from_trimesh(mesh_transformed, smooth=False)\n",
    "    scene.add(pyrender_mesh, pose=np.eye(4))\n",
    "    \n",
    "    # Render\n",
    "    renderer = pyrender.OffscreenRenderer(W, H)\n",
    "    color, depth = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "    \n",
    "    return color, depth\n",
    "\n",
    "def visualize_comparison(mesh, pose, scene_dir, i:int=0):\n",
    "    reader = Ho3dReader(video_dir=scene_dir, root_dir='/Experiments/simonep01/ho3d')\n",
    "    rgb = reader.get_color(i)\n",
    "    \n",
    "    # Check if mesh is a file path or trimesh object\n",
    "    if isinstance(mesh, str):\n",
    "        mesh = trimesh.load(mesh)\n",
    "\n",
    "    H, W = rgb.shape[:2]\n",
    "    # Render mesh at gt_pose\n",
    "    rendered, depth = render_mesh_at_pose(mesh, pose, reader.K, H, W)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(rgb)\n",
    "    axes[0].set_title('Original RGB Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Rendered mesh\n",
    "    axes[1].imshow(rendered)\n",
    "    axes[1].set_title('Rendered Mesh at GT Pose')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = rgb.copy()\n",
    "    mask = rendered.sum(axis=2) > 0\n",
    "    overlay[mask] = rendered[mask] * 0.6 + rgb[mask] * 0.4\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title('Overlay (60% mesh, 40% RGB)')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_confidence_pointcloud(CMesh):\n",
    "    \"\"\"Visualize mesh vertices as colored point cloud by confidence\n",
    "    \n",
    "    Colors: red (0) → orange (0-0.25) → yellow (0.25-0.5) → blue (0.5-1) → green (1)\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    # Assign colors based on confidence\n",
    "    colors = np.zeros((len(CMesh.confidence), 3), dtype=np.uint8)\n",
    "    \n",
    "    mask_zero = CMesh.confidence == 0\n",
    "    mask_low = (CMesh.confidence > 0) & (CMesh.confidence < 0.25)\n",
    "    mask_mid = (CMesh.confidence >= 0.25) & (CMesh.confidence < 0.5)\n",
    "    mask_high = (CMesh.confidence >= 0.5) & (CMesh.confidence < 1)\n",
    "    mask_one = CMesh.confidence >= 1.0\n",
    "    \n",
    "    colors[mask_zero] = [255, 0, 0]      # Red\n",
    "    colors[mask_low] = [255, 125, 0]     # Orange\n",
    "    colors[mask_mid] = [255, 255, 0]     # Yellow\n",
    "    colors[mask_high] = [0, 0, 255]      # Blue\n",
    "    colors[mask_one] = [0, 255, 0]       # Green\n",
    "    \n",
    "    # Create plotly scatter3d\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=CMesh.observed_positions[:, 0],\n",
    "        y=CMesh.observed_positions[:, 1],\n",
    "        z=CMesh.observed_positions[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=2, color=[f'rgb({c[0]},{c[1]},{c[2]})' for c in colors])\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene=dict(aspectmode='data'),\n",
    "        title=f'Confidence: {mask_zero.sum()} red (0), {mask_low.sum()} orange (0-0.25), '\n",
    "              f'{mask_mid.sum()} yellow (0.25-0.5), {mask_high.sum()} blue (0.5-1), {mask_one.sum()} green (1)'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cbfef",
   "metadata": {},
   "source": [
    "## First frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4487e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'AP14'\n",
    "mesh_file= f'/Experiments/simonep01/ho3d/first_frame_instantmeshes/{video_id}/mesh.obj'\n",
    "test_scene_dir= f'/Experiments/simonep01/ho3d/evaluation/{video_id}'\n",
    "est_refine_iter= 5\n",
    "track_refine_iter= 2\n",
    "n_frames = 100\n",
    "debug= 0\n",
    "debug_dir= f'debug/{video_id}_{n_frames}'\n",
    "attach_every_n_frames= 5\n",
    "\n",
    "set_logging_format()\n",
    "set_seed(0)\n",
    "\n",
    "os.system(f'rm -rf {debug_dir}/* && mkdir -p {debug_dir}/track_vis {debug_dir}/ob_in_cam')\n",
    "\n",
    "log_path = os.path.join(debug_dir, 'log.txt')\n",
    "file_handler = logging.FileHandler(log_path, mode='w')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "logging.getLogger().addHandler(file_handler)\n",
    "\n",
    "mesh = trimesh.load(mesh_file)\n",
    "\n",
    "reader = Ho3dReader(video_dir=test_scene_dir)\n",
    "\n",
    "mesh, _ = estimate_and_scale_mesh(mesh,reader)\n",
    "\n",
    "CMesh = MeshWithConfidence(mesh)\n",
    "\n",
    "to_origin, extents = trimesh.bounds.oriented_bounds(CMesh.mesh)\n",
    "bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)\n",
    "\n",
    "scorer = ScorePredictor()\n",
    "refiner = PoseRefinePredictor()\n",
    "glctx = dr.RasterizeCudaContext()\n",
    "est = FoundationPose(model_pts=CMesh.mesh.vertices, model_normals=CMesh.mesh.vertex_normals, mesh=CMesh.mesh, scorer=scorer, refiner=refiner, debug_dir=debug_dir, debug=debug, glctx=glctx)\n",
    "logging.info(\"estimator initialization done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df368fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh = reader.get_gt_mesh()\n",
    "pts_gt_orig = np.array(gt_mesh.vertices, dtype=np.float32)\n",
    "\n",
    "metrics = {\n",
    "    'ADD': 0.0,\n",
    "    'ADI': 0.0,\n",
    "    '3D_IOU': 0.0,\n",
    "    'Chamfer': 0.0\n",
    "}\n",
    "\n",
    "per_frame_metrics = {key: [] for key in metrics.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_metrics import add, adi_est, chamfer_distance\n",
    "def evaluate_frame(est_mesh, pose, gt_pose):\n",
    "    pts_est_orig = np.array(est_mesh.vertices, dtype=np.float32)\n",
    "    R_est, t_est = pose_to_Rt(pose)\n",
    "    R_gt, t_gt = pose_to_Rt(gt_pose)\n",
    "    frame_metrics = {}\n",
    "    frame_metrics['ADD'] = add(R_est=R_est, t_est=t_est, R_gt=R_gt, t_gt=t_gt, pts=pts_gt_orig)\n",
    "    frame_metrics['3D_IOU'], frame_metrics['ADI'] = adi_est(R_est, t_est, pts_est_orig, R_gt, t_gt, pts_gt_orig)\n",
    "    frame_metrics['Chamfer'] = chamfer_distance(R_est, t_est, pts_est_orig, R_gt, t_gt, pts_gt_orig)\n",
    "    return frame_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ee410",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "color = reader.get_color(i)\n",
    "depth = reader.get_depth(i)\n",
    "mask = reader.get_mask(i).astype(bool)\n",
    "pose = est.register(K=reader.K, rgb=color, depth=depth, ob_mask=mask, iteration=est_refine_iter)\n",
    "\n",
    "tmp_mesh = CMesh.mesh.copy()\n",
    "\n",
    "if attach_every_n_frames > 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "                metrics[key] += frame_metrics[key]\n",
    "                per_frame_metrics[key].append(frame_metrics[key])\n",
    "\n",
    "os.makedirs(f'{debug_dir}/ob_in_cam', exist_ok=True)\n",
    "np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMesh.mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf11441",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a49359",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_confidence_pointcloud(CMesh)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ee043",
   "metadata": {},
   "source": [
    "## Following Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37315465",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 5:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "#fig = visualize_confidence_pointcloud(CMesh)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbfec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ac806",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMesh.mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710077a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 10:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "#fig = visualize_confidence_pointcloud(CMesh)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d66fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 25-1:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "#fig = visualize_confidence_pointcloud(CMesh)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0976e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 50-1:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "#fig = visualize_confidence_pointcloud(CMesh)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843804cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18513af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 100-1:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "#fig = visualize_confidence_pointcloud(CMesh)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1913c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMesh.mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e99920",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 200-1:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "fig = visualize_confidence_pointcloud(CMesh)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a76234",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMesh.mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 400-1:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "fig = visualize_confidence_pointcloud(CMesh)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1814dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMesh.mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f76f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 600-1:\n",
    "    i+=1\n",
    "    color = reader.get_color(i)\n",
    "    depth = reader.get_depth(i)\n",
    "    pose = est.track_one(rgb=color, depth=depth, K=reader.K, iteration=track_refine_iter)\n",
    "    \n",
    "    tmp_mesh = CMesh.mesh.copy()\n",
    "    if attach_every_n_frames > 0 and i % attach_every_n_frames == 0:\n",
    "        CMesh = perform_attachment(est, CMesh, pose, reader, i)\n",
    "        frame_metrics = evaluate_frame(tmp_mesh, pose, reader.get_gt_pose(i))\n",
    "        for key in metrics.keys():\n",
    "            metrics[key] += frame_metrics[key]\n",
    "            per_frame_metrics[key].append(frame_metrics[key])\n",
    "    \n",
    "    np.savetxt(f'{debug_dir}/ob_in_cam/{reader.id_strs[i]}.txt', pose.reshape(4,4))\n",
    "\n",
    "fig = visualize_confidence_pointcloud(CMesh)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb271601",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMesh.mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fa49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_comparison(tmp_mesh, pose, test_scene_dir, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e83652",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = i+1\n",
    "eval_dir = f\"{debug_dir}/evaluation_results\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "for key in metrics:\n",
    "    metrics[key] /= n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451881b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary as JSON\n",
    "summary_data = {\n",
    "    'num_frames': n_frames,\n",
    "    'metrics': {}\n",
    "}\n",
    "\n",
    "for key in metrics.keys():\n",
    "    summary_data['metrics'][key] = {\n",
    "        'mean': float(metrics[key]),\n",
    "        'min': float(np.min(per_frame_metrics[key])),\n",
    "        'max': float(np.max(per_frame_metrics[key]))\n",
    "    }\n",
    "\n",
    "summary_file = os.path.join(eval_dir, 'summary.json')\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary_data, f, indent=2)\n",
    "print(f\"Saved summary to: {summary_file}\")\n",
    "\n",
    "\n",
    "# Save per-frame metrics as JSON\n",
    "for key in metrics.keys():\n",
    "    per_frame_data = {\n",
    "        'metric': key,\n",
    "        'num_frames': n_frames,\n",
    "        'values': [float(v) for v in per_frame_metrics[key]]\n",
    "    }\n",
    "    output_file = os.path.join(eval_dir, f'{key}_per_frame.json')\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(per_frame_data, f, indent=2)\n",
    "print(f\"Saved per-frame results to: {eval_dir}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Evaluation Results ({n_frames} frames)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ADI (Average Distance):        {metrics['ADI']:.4f} mm\")\n",
    "print(f\"3D IOU:                        {metrics['3D_IOU']:.3f} %\")\n",
    "print(f\"Chamfer Distance:              {metrics['Chamfer']:.4f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting code\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Per-Frame Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (metric_name, values) in enumerate(per_frame_metrics.items()):\n",
    "    axes[idx].plot(range(len(values)), values, marker='o', markersize=4, linewidth=2)\n",
    "    axes[idx].set_xlabel('Frame Number')\n",
    "    axes[idx].set_ylabel(metric_name)\n",
    "    axes[idx].set_title(f'{metric_name} over Frames')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{eval_dir}metrics_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundationpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
