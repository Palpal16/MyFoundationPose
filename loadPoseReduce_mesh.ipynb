{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d10a30",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0541dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111489a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import trimesh\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datareader import Ho3dReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add7ea2",
   "metadata": {},
   "source": [
    "# Select mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1691f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'SM1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_dir = f'/home/simonep01/sam-3d-objects/meshes/{video_id}'\n",
    "output = torch.load(f'{sam_dir}/output_data.pt', map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6e1ea",
   "metadata": {},
   "source": [
    "# Load and pose mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40421264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.transforms import quaternion_to_matrix, Transform3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "_R_ZUP_TO_YUP = np.array([[1, 0, 0], [0, 0, -1], [0, 1, 0]], dtype=np.float32)\n",
    "_R_YUP_TO_ZUP = _R_ZUP_TO_YUP.T\n",
    "my_rotation = np.array([[-1, 0, 0], [0, 1, 0], [0, 0, -1]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_transform(\n",
    "    scale: torch.Tensor, rotation: torch.Tensor, translation: torch.Tensor\n",
    ") -> Transform3d:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scale: (..., 3) tensor of scale factors\n",
    "        rotation: (..., 3, 3) tensor of rotation matrices\n",
    "        translation: (..., 3) tensor of translation vectors\n",
    "    \"\"\"\n",
    "    tfm = Transform3d(dtype=scale.dtype, device=scale.device)\n",
    "    return tfm.scale(scale).rotate(rotation).translate(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = output['glb'].copy()\n",
    "mesh.export(f'{sam_dir}/initial_mesh.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6586f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert from Y-up (OBJ) to Z-up (transform space)\n",
    "vertices = mesh.vertices.astype(np.float32) @ _R_YUP_TO_ZUP\n",
    "vertices_tensor = torch.from_numpy(vertices).float().to(output[\"rotation\"].device)\n",
    "\n",
    "# 2. Apply transformation in Z-up space\n",
    "R_l2c = quaternion_to_matrix(output['rotation'])\n",
    "l2c_transform = compose_transform(\n",
    "    scale=output['scale'],\n",
    "    rotation=R_l2c,\n",
    "    translation=output['translation'],\n",
    ")\n",
    "vertices_transformed = l2c_transform.transform_points(vertices_tensor.unsqueeze(0))\n",
    "mesh.vertices = vertices_transformed.squeeze(0).cpu().numpy() @ my_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cacfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.export(f'{sam_dir}/transformed_mesh.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417fbf1",
   "metadata": {},
   "source": [
    "# Downsample mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load(f'{sam_dir}/transformed_mesh.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5581b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_mesh_best_quality(mesh, target_vertices):\n",
    "    \"\"\"\n",
    "    Best quality mesh downsampling using direct quadric decimation.\n",
    "    Preserves topology, sharp features, and minimizes geometric error.\n",
    "    \n",
    "    Args:\n",
    "        mesh: input mesh\n",
    "        target_vertices: Target number of vertices\n",
    "    \"\"\"\n",
    "    print(f\"Original: {len(mesh.vertices)} vertices, {len(mesh.faces)} faces\")\n",
    "    \n",
    "    # Convert to Open3D mesh (preserve colors)\n",
    "    mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "    mesh_o3d.vertices = o3d.utility.Vector3dVector(mesh.vertices)\n",
    "    mesh_o3d.triangles = o3d.utility.Vector3iVector(mesh.faces)\n",
    "    \n",
    "    # Preserve vertex colors if available\n",
    "    colors = mesh.visual.vertex_colors[:, :3] / 255.0\n",
    "    mesh_o3d.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    # Compute vertex normals for better quality\n",
    "    mesh_o3d.compute_vertex_normals()\n",
    "    \n",
    "    # Quadric edge collapse decimation\n",
    "    # Target triangles â‰ˆ 2 * target_vertices for closed meshes\n",
    "    target_triangles = target_vertices * 2\n",
    "    \n",
    "    mesh_simplified = mesh_o3d.simplify_quadric_decimation(\n",
    "        target_number_of_triangles=target_triangles\n",
    "    )\n",
    "    \n",
    "    print(f\"Simplified: {len(mesh_simplified.vertices)} vertices, \"\n",
    "          f\"{len(mesh_simplified.triangles)} faces\")\n",
    "    \n",
    "    # Convert back to trimesh\n",
    "    vertices_out = np.asarray(mesh_simplified.vertices)\n",
    "    faces_out = np.asarray(mesh_simplified.triangles)\n",
    "    \n",
    "    colors_out = (np.asarray(mesh_simplified.vertex_colors) * 255).astype(np.uint8)\n",
    "    mesh_out = trimesh.Trimesh(\n",
    "        vertices=vertices_out,\n",
    "        faces=faces_out,\n",
    "        vertex_colors=colors_out\n",
    "    )\n",
    "    \n",
    "    # Optional: Remove degenerate faces and fix normals\n",
    "    mask = mesh_out.nondegenerate_faces()\n",
    "    mesh_out.update_faces(mask)\n",
    "    \n",
    "    # Remove infinite/nan values\n",
    "    mesh_out.remove_infinite_values()\n",
    "    \n",
    "    # Fix normals (use repair module)\n",
    "    trimesh.repair.fix_normals(mesh_out)\n",
    "    \n",
    "    return mesh_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "mesh_simplified = downsample_mesh_best_quality(\n",
    "    mesh=mesh,\n",
    "    target_vertices=60000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_simplified.export(f'{sam_dir}/reduced_mesh.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_simplified.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundationpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
